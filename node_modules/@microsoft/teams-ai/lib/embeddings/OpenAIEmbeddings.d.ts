/**
 * @module teams-ai
 */
/**
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License.
 */
import { AxiosResponse, AxiosRequestConfig } from 'axios';
import { EmbeddingsModel, EmbeddingsResponse } from '../types/EmbeddingsModel';
import { CreateEmbeddingRequest, CreateEmbeddingResponse } from '../internals';
/**
 * Base model options common to both OpenAI and Azure OpenAI services.
 */
export interface BaseOpenAIEmbeddingsOptions {
    /**
     * Optional. Number of dimensions to use when generating embeddings.
     * @remarks
     * Only valid for embedding models that support dynamic dimensionality.
     */
    dimensions?: number;
    /**
     * Optional. Whether to log requests to the console.
     * @remarks
     * This is useful for debugging prompts and defaults to `false`.
     */
    logRequests?: boolean;
    /**
     * Optional. Retry policy to use when calling the OpenAI API.
     * @remarks
     * The default retry policy is `[2000, 5000]` which means that the first retry will be after
     * 2 seconds and the second retry will be after 5 seconds.
     */
    retryPolicy?: number[];
    /**
     * Optional. Request options to use when calling the OpenAI API.
     */
    requestConfig?: AxiosRequestConfig;
}
/**
 * Options for configuring an `OpenAIEmbeddings` to generate embeddings using an OpenAI hosted model.
 */
export interface OpenAIEmbeddingsOptions extends BaseOpenAIEmbeddingsOptions {
    /**
     * API key to use when calling the OpenAI API.
     * @remarks
     * A new API key can be created at https://platform.openai.com/account/api-keys.
     */
    apiKey: string;
    /**
     * Embeddings Model to use.
     */
    model: string;
    /**
     * Optional. Organization to use when calling the OpenAI API.
     */
    organization?: string;
    /**
     * Optional. Endpoint to use when calling the OpenAI API.
     * @remarks
     * For Azure OpenAI this is the deployment endpoint.
     */
    endpoint?: string;
}
/**
 * Options for configuring an embeddings object that calls an `OpenAI` compliant endpoint.
 * @remarks
 * The endpoint should comply with the OpenAPI spec for OpenAI's API:
 * https://github.com/openai/openai-openapi
 * And an example of a compliant endpoint is LLaMA.cpp's reference server:
 * https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md
 */
export interface OpenAILikeEmbeddingsOptions extends BaseOpenAIEmbeddingsOptions {
    /**
     * Endpoint of the embeddings server to call.
     */
    endpoint: string;
    /**
     * Embeddings Model to use.
     */
    model: string;
    /**
     * Optional. API key to use when calling the embeddings server.
     */
    apiKey?: string;
}
/**
 * Options for configuring an `OpenAIEmbeddings` to generate embeddings using an Azure OpenAI hosted model.
 */
export interface AzureOpenAIEmbeddingsOptions extends BaseOpenAIEmbeddingsOptions {
    /**
     * API key to use when making requests to Azure OpenAI.
     */
    azureApiKey: string;
    /**
     * Deployment endpoint to use.
     */
    azureEndpoint: string;
    /**
     * Name of the Azure OpenAI deployment (model) to use.
     */
    azureDeployment: string;
    /**
     * Optional. Version of the API being called. Defaults to `2023-05-15`.
     */
    azureApiVersion?: string;
}
/**
 * A `EmbeddingsModel` for calling OpenAI and Azure OpenAI hosted models.
 */
export declare class OpenAIEmbeddings implements EmbeddingsModel {
    private readonly _httpClient;
    private readonly _useAzure;
    private readonly UserAgent;
    /**
     * Options the client was configured with.
     */
    readonly options: OpenAIEmbeddingsOptions | AzureOpenAIEmbeddingsOptions | OpenAILikeEmbeddingsOptions;
    /**
     * Creates a new `OpenAIEmbeddings` instance.
     * @param {OpenAIEmbeddingsOptions | AzureOpenAIEmbeddingsOptions | OpenAILikeEmbeddingsOptions} options Options for configuring the embeddings client.
     */
    constructor(options: OpenAIEmbeddingsOptions | AzureOpenAIEmbeddingsOptions);
    /**
     * Creates embeddings for the given inputs using the OpenAI API.
     * @param {string} model Name of the model to use (or deployment for Azure).
     * @param {string | string[]} inputs Text inputs to create embeddings for.
     * @returns {Promise<EmbeddingsResponse>} A `EmbeddingsResponse` with a status and the generated embeddings or a message when an error occurs.
     */
    createEmbeddings(model: string, inputs: string | string[]): Promise<EmbeddingsResponse>;
    /**
     * @private
     * @param {CreateEmbeddingRequest} request The request to send to the OpenAI API.
     * @returns {Promise<AxiosResponse<CreateEmbeddingResponse>>} A promise that resolves to the response from the OpenAI API.
     */
    protected createEmbeddingRequest(request: CreateEmbeddingRequest): Promise<AxiosResponse<CreateEmbeddingResponse>>;
    /**
     * @private
     * @template TData Optional. Type of the data associated with the action.
     * @param {string} url The URL to send the request to.
     * @param {object} body The body of the request.
     * @param {number} retryCount The number of times the request has been retried.
     * @returns {Promise<AxiosResponse<TData>>} A promise that resolves to the response from the OpenAI API.
     */
    protected post<TData>(url: string, body: object, retryCount?: number): Promise<AxiosResponse<TData>>;
}
//# sourceMappingURL=OpenAIEmbeddings.d.ts.map