import { TurnContext } from 'botbuilder';
import { Memory } from '../MemoryFork';
import { PromptCompletionModel } from '../models';
import { PromptFunctions, PromptTemplate } from '../prompts';
import { Tokenizer } from '../tokenizers';
import { PromptResponse } from '../types';
export interface LlamaModelOptions {
    apiKey: string;
    endpoint: string;
    logRequests?: boolean;
}
export declare class LlamaModel implements PromptCompletionModel {
    readonly options: LlamaModelOptions;
    private readonly _httpClient;
    constructor(options: LlamaModelOptions);
    completePrompt(context: TurnContext, memory: Memory, functions: PromptFunctions, tokenizer: Tokenizer, template: PromptTemplate): Promise<PromptResponse<string>>;
}
//# sourceMappingURL=LlamaModel.d.ts.map