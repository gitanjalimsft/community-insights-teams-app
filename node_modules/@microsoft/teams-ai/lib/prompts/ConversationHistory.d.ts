/**
 * @module teams-ai
 */
/**
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License.
 */
import { Message } from './Message';
import { PromptFunctions } from './PromptFunctions';
import { RenderedPromptSection } from './PromptSection';
import { PromptSectionBase } from './PromptSectionBase';
import { TurnContext } from 'botbuilder';
import { Tokenizer } from '../tokenizers';
import { Memory } from '../MemoryFork';
/**
 * A section that renders the conversation history.
 */
export declare class ConversationHistory extends PromptSectionBase {
    readonly variable: string;
    readonly userPrefix: string;
    readonly assistantPrefix: string;
    /**
     * Creates a new 'ConversationHistory' instance.
     * @param {string} variable - Name of memory variable used to store the histories `Message[]`.
     * @param {number} tokens - Optional. Sizing strategy for this section. Defaults to `proportional` with a value of `1.0`.
     * @param {boolean} required - Optional. Indicates if this section is required. Defaults to `false`.
     * @param {string} userPrefix - Optional. Prefix to use for user messages when rendering as text. Defaults to `user: `.
     * @param {string} assistantPrefix - Optional. Prefix to use for assistant messages when rendering as text. Defaults to `assistant: `.
     * @param {string} separator - Optional. Separator to use between messages when rendering as text. Defaults to `\n`.
     */
    constructor(variable: string, tokens?: number, required?: boolean, userPrefix?: string, assistantPrefix?: string, separator?: string);
    /**
     * @param {TurnContext} context - Context for the current turn of conversation.
     * @param {Memory} memory - Memory to use for rendering.
     * @param {PromptFunctions} functions - Prompt functions to use for rendering.
     * @param {Tokenizer} tokenizer - Tokenizer to use for encoding text.
     * @param {number} maxTokens - Maximum number of tokens allowed.
     * @returns {Promise<RenderedPromptSection<string>>} Rendered prompt section as a string.
     * @private
     */
    renderAsText(context: TurnContext, memory: Memory, functions: PromptFunctions, tokenizer: Tokenizer, maxTokens: number): Promise<RenderedPromptSection<string>>;
    /**
     * @private
     * @param {TurnContext} context - Context for the current turn of conversation.
     * @param {Memory} memory - Memory to use for rendering.
     * @param {PromptFunctions} functions - Prompt functions to use for rendering.
     * @param {Tokenizer} tokenizer - Tokenizer to use for encoding text.
     * @param {number} maxTokens - Maximum number of tokens allowed.
     * @returns {Promise<RenderedPromptSection<Message[]>>} Rendered prompt section as a list of messages.
     */
    renderAsMessages(context: TurnContext, memory: Memory, functions: PromptFunctions, tokenizer: Tokenizer, maxTokens: number): Promise<RenderedPromptSection<Message[]>>;
}
//# sourceMappingURL=ConversationHistory.d.ts.map