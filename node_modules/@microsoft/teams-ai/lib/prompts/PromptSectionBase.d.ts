/**
 * @module teams-ai
 */
/**
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License.
 */
import { Message } from './Message';
import { PromptFunctions } from './PromptFunctions';
import { PromptSection, RenderedPromptSection } from './PromptSection';
import { TurnContext } from 'botbuilder';
import { Tokenizer } from '../tokenizers';
import { Memory } from '../MemoryFork';
/**
 * Abstract Base class for most prompt sections.
 * @remarks
 * This class provides a default implementation of `renderAsText()` so that derived classes only
 * need to implement `renderAsMessages()`.
 */
export declare abstract class PromptSectionBase implements PromptSection {
    readonly required: boolean;
    readonly tokens: number;
    readonly separator: string;
    readonly textPrefix: string;
    /**
     * Creates a new 'PromptSectionBase' instance.
     * @param {number} tokens - Optional. Sizing strategy for this section. Defaults to -1, 'auto'.
     * @param {boolean} required - Optional. Indicates if this section is required. Defaults to `true`.
     * @param {string} separator - Optional. Separator to use between sections when rendering as text. Defaults to `\n`.
     * @param {string} textPrefix - Optional. Prefix to use for text output. Defaults to an empty string.
     */
    constructor(tokens?: number, required?: boolean, separator?: string, textPrefix?: string);
    /**
     * Renders the prompt section as a string of text.
     * @param {TurnContext} context - Context for the current turn of conversation.
     * @param {Memory} memory - Interface for accessing state variables.
     * @param {PromptFunctions} functions - Functions for rendering prompts.
     * @param {Tokenizer} tokenizer - Tokenizer to use for encoding/decoding text.
     * @param {number} maxTokens - Maximum number of tokens allowed for the rendered prompt.
     * @returns {Promise<RenderedPromptSection<string>>} The rendered prompt section.
     */
    renderAsText(context: TurnContext, memory: Memory, functions: PromptFunctions, tokenizer: Tokenizer, maxTokens: number): Promise<RenderedPromptSection<string>>;
    /**
     * Renders the prompt section as a list of `Message` objects.
     * @remarks
     * MUST be implemented by derived classes.
     * @param {TurnContext} context - Context for the current turn of conversation.
     * @param {Memory} memory - Interface for accessing state variables.
     * @param {PromptFunctions} functions - Functions for rendering prompts.
     * @param {Tokenizer} tokenizer - Tokenizer to use for encoding/decoding text.
     * @param {number} maxTokens - Maximum number of tokens allowed for the rendered prompt.
     * @returns {Promise<RenderedPromptSection<Message<any>[]>>} The rendered prompt section.
     */
    abstract renderAsMessages(context: TurnContext, memory: Memory, functions: PromptFunctions, tokenizer: Tokenizer, maxTokens: number): Promise<RenderedPromptSection<Message<any>[]>>;
    /**
     * Calculates the token budget for the prompt section.
     * @remarks
     * If the section has a fixed length, the budget will be the minimum of the section's length
     * and the maximum number of tokens. Otherwise, the budget will be the maximum number of tokens.
     * @param {number} maxTokens - Maximum number of tokens allowed for the rendered prompt.
     * @returns {number} The token budget for the prompt section.
     */
    protected getTokenBudget(maxTokens: number): number;
    /**
     * Helper method for returning a list of messages from `renderAsMessages()`.
     * @remarks
     * If the section has a fixed length, the function will truncate the list of messages to
     * fit within the token budget.
     * @param {Message[]} output - List of messages to return.
     * @param {number} length Total number of tokens consumed by the list of messages.
     * @param {Tokenizer} tokenizer Tokenizer to use for encoding/decoding text.
     * @param {number} maxTokens Maximum number of tokens allowed for the rendered prompt.
     * @returns {RenderedPromptSection<Message[]>} The rendered prompt section.
     */
    protected returnMessages(output: Message[], length: number, tokenizer: Tokenizer, maxTokens: number): RenderedPromptSection<Message[]>;
    /**
     * Returns the content of a message as a string.
     * @param {Message} message - Message to get the text of.
     * @returns {string} The message content as a string.
     */
    static getMessageText(message: Message): string;
}
//# sourceMappingURL=PromptSectionBase.d.ts.map